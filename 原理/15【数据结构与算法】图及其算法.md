## 图的概念

非线性表数据结构，图（Graph）

树中的元素我们称为节点，图中的元素我们就叫做顶点（vertex）。

顶点的度（degree），就是跟顶点相连接的边的条数。

边有方向的图叫做“有向图”，边没有方向的图就叫做“无向图”。

无向图中有“度”这个概念，表示一个顶点有多少条边。在有向图中，我们把度分为入度（In-degree）和出度（Out-degree）。

顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。

带权图（weighted graph）。在带权图中，每条边都有一个权重（weight）。

## 图的表示

两种标准表示法：一种表示法将图作为**邻接链表**的组合，另一种表示法则将图作为**邻接矩阵**来看待。两种表示法既可以表示无向图，也可以表示有向图。

<span style='color:red'>邻接链表通常用来表示稀疏图（边的条数远远小于|V|^2的图），其表示非常紧凑</span>

<span style='color:red'>在稠密图的（|E|接近|V|^2的图）情况下，倾向于使用邻接矩阵表示法</span>

<span style='color:red'>如果需要快速判断任意两个结点之间是否有边相连，可能也需要使用邻接矩阵表示法</span>

### 邻接链表表示法

邻接表（Adjacency List）

邻接链表表示由一个包含|V|条链表的数组Adj所构成，每个结点有一个链表。对于每个结点u，邻接链表Adj[u]包含所有与结点u之间有边相连的结点v（也可以说，该链表里包含指向这些结点的指针）

所有邻接链表的长度之和等于|E|（有向图）或2|E|（无向图）。

优缺点

- 不管是无向图还是有向图，邻接链表表示法的存储空间需求为$\Theta(V+E)$

- 邻接链表的鲁棒性很高，可以对其进行简单修改来支持许多其他的图变种。如表示权重图时，可以将权重存放在相应结点的邻接链表里。

- 潜在缺陷：无法快速判断一条边(u,v)是否是图中的一条边，唯一的办法是在邻接链表Adj[u]里面搜索结点v。
- 邻接矩阵存储起来比较浪费空间，但是使用起来比较节省时间。相反，邻接表存储起来比较节省空间，但是使用起来就比较耗时间。
- 我们可以将邻接表中的链表改成平衡二叉查找树。实际开发中，我们可以选择用红黑树。这样，我们就可以更加快速地查找两个顶点之间是否存在边了。当然，这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。

### 邻接矩阵表示法

图最直观的一种存储方法就是，邻接矩阵（Adjacency Matrix）。

邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j]和 A[j][i]标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j]标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i]标记为 1。对于带权图，数组中就存储相应的权重。

优缺点

- 存储方式简单、直接，克服了邻接链表的缺陷，可以快速判断一条边的存在，但付出的代价是更大的存储空间消耗。
- 如果我们存储的是稀疏图（Sparse Matrix），也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。

- 不管一个图有多少条边，邻接矩阵的空间需求皆为$\Theta(V^2)$​。
- 用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。比如求解最短路径问题时会提到一个Floyd-Warshall 算法，就是利用矩阵循环相乘若干次得到结果。

- 虽然邻接链表表示法和邻接矩阵表示法在渐进意义下至少是一样空间有效的，但邻接矩阵表示法更为简单，因此在图规模比较小时，我们可能更倾向于使用邻接矩阵表示法。而且，对于无向图来说，邻接矩阵还有一个优势：每个记录项只需要1位的空间。

### 如何存储微博、微信等社交网络中的好友关系？

微博、微信是两种“图”，前者是有向图，后者是无向图。在这个问题上，两者的解决思路差不多，所以我只拿微博来讲解。

数据结构是为算法服务的，所以具体选择哪种存储方法，与期望支持的操作有关系。针对微博用户关系，假设我们需要支持下面这样几个操作：

- 判断用户 A 是否关注了用户 B；
- 判断用户 A 是否是用户 B 的粉丝；
- 用户 A 关注用户 B；
- 用户 A 取消关注用户 B；
- 根据用户名称的首字母排序，分页获取用户的粉丝列表；
- 根据用户名称的首字母排序，分页获取用户的关注列表。

关于如何存储一个图，前面我们讲到两种主要的存储方法，邻接矩阵和邻接表。因为社交网络是一张稀疏图，使用邻接矩阵存储比较浪费存储空间。所以，这里我们采用邻接表来存储。

不过，用一个邻接表来存储这种有向图是不够的。我们去查找某个用户关注了哪些用户非常容易，但是如果要想知道某个用户都被哪些用户关注了，也就是用户的粉丝列表，是非常困难的。

基于此，我们需要一个逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系。对应到图上，邻接表中，每个顶点的链表中，存储的就是这个顶点指向的顶点，逆邻接表中，每个顶点的链表中，存储的是指向这个顶点的顶点。如果要查找某个用户关注了哪些用户，我们可以在邻接表中查找；如果要查找某个用户被哪些用户关注了，我们从逆邻接表中查找。

基础的邻接表不适合快速判断两个用户之间是否是关注与被关注的关系，所以我们选择改进版本，将邻接表中的链表改为支持快速查找的动态数据结构。选择哪种动态数据结构呢？红黑树、跳表、有序动态数组还是散列表呢？

因为我们需要按照用户名称的首字母排序，分页来获取用户的粉丝列表或者关注列表，用跳表这种结构再合适不过了。这是因为，跳表插入、删除、查找都非常高效，时间复杂度是 O(logn)，空间复杂度上稍高，是 O(n)。最重要的一点，跳表中存储的数据本来就是有序的了，分页获取粉丝列表或关注列表，就非常高效。

如果对于小规模的数据，比如社交网络中只有几万、几十万个用户，我们可以将整个社交关系存储在内存中，上面的解决思路是没有问题的。但是如果像微博那样有上亿的用户，数据规模太大，我们就无法全部存储在内存中了。这个时候该怎么办呢？

我们可以通过哈希算法等数据分片方式，将邻接表存储在不同的机器上。你可以看下面这幅图，我们在机器 1 上存储顶点 1，2，3 的邻接表，在机器 2 上，存储顶点 4，5 的邻接表。逆邻接表的处理方式也一样。当要查询顶点与顶点关系的时候，我们就利用同样的哈希算法，先定位顶点所在的机器，然后再在相应的机器上查找。

除此之外，我们还有另外一种解决思路，就是利用外部存储（比如硬盘），因为外部存储的存储空间要比内存会宽裕很多。数据库是我们经常用来持久化存储关系数据的，所以我这里介绍一种数据库的存储方式。

我用下面这张表来存储这样一个图。为了高效地支持前面定义的操作，我们可以在表上建立多个索引，比如第一列、第二列，给这两列都建立索引。

![img](img/7339595c631660dc87559bec2ddf928f.jpg)



## 广度优先搜索

为了跟踪算法的进展，广度优先搜索在概念上将每个结点涂上白色、灰色或黑色。所有结点在一开始的时候均涂上白色。所有与黑色结点邻接的结点都已经被发现。对于灰色结点来说，其邻接结点可能存在未被发现的白色结点。

在执行广度优先搜索的过程中将构造出一棵广度优先树。一开始，该树仅含有根结点，就是源结点s。在扫描已发现结点u的邻接链表时，每当发现一个白色结点v，就将结点v和边(u,v)同时加入该棵树中。在广度优先树中，称结点u是结点v的前驱或者父结点。每个结点最多只有一个父结点π。u.d记录广度优先搜索算法所计算出的从源结点s到结点u之间的距离。Q是一个先进先出的队列，用来管理灰色结点集。

```
BFS(G,s)
for each vertex u∈G.V-{s}
	u.color=WHITE
	u.d=∞
	u.π=NIL
s.color=GRAY
s.d=0
s.π=NIL
Q=∅
ENQUEUE(Q,s)
while Q≠∅
	u=DEQUEUE(Q)
	for each v∈G.Adj[u]
		if v.color == WHITE
			v.color=GRAY
			v.d=u.d+1
			v.π=u
			ENQUEUE(Q,v)
	u.colo=BLACK
```

广度优先搜索的总运行时间为O(V+E)，结点入队出队的时间总和为O(V)，扫描每个邻接链表的时间总和为O(E)。

### 最短路径

定义从源结点s到结点v的最短路径距离$\delta(s,v)$

**引理**

给定G=(V,E)，G为一个有向图或无向图，设s∈V为任意结点，则对于任意边$(u,v)\in E，\delta(s,v)\le \delta(s,u)+1$

**v.d是$\delta(s,v)$的一个上界**

设G=(V,E)为一个有向图或无向图，假定BFS以给定结点$s\in V$作为源结点在图G上运行。那么在BFS终结时，对于每个结点$v\in V$，BFS所计算出的v.d满足$v.d\ge \delta(s,v)$。

**在任意时刻，队列里面最多包含两个不同的d值**

假定BFS在图G=(V,E)上运行的过程中，队列Q包含的结点为$<v_1,v_2,...,v_r>$，这里v1是队列Q的头，vr是队列Q的尾。那么$v_r.d\le v_1.d+1$，并且对于i=1,2,...,r-1，$v_i.d\le v_{i+1}.d+1$.

**在结点加入到队列时，d值随时间推移单调增长。**

假定在执行BFS时，结点vi和结点vj都加入到队列Q里，并且vi在vj前面入队，则在vj入队时，我们有$v_i.d\le v_j.d$

**广度优先搜索的正确性**

设G=(V,E)为一个有向图或无向图，又假设BFS以s为源结点在图G上运行。那么在算法执行过程中，BFS将发现从源结点s可以到达的所有结点$v\in V$，并在算法终止时，对于所有的$v\in V，v.d=\delta(s,v)$。而且，对于任意可以从s到达的结点$v\ne s$，从源结点s到结点v的其中一条路径为从结点s到结点v.π的最短路径再加上边(v.π，v).

### 广度优先树

过程BFS在对图进行搜索的过程中将创建一棵广度优先树，该棵树对应的是$\pi$属性。更形式化地说，对于图G=(V,E)和源结点s，我们定义图G的前驱子图为$G_{\pi}=(V_{\pi}, E_{\pi})$，其中

$V_{\pi}=\{v\in V：v.\pi \ne NIL\}\cup\{s\}，E_{\pi}=\{(v.{\pi},v)：v\in V_{\pi}—\{s\}\}$

如果$V_{\pi}$由从源结点s可以到达的结点组成，并且对于所有的$v\in V_{\pi}$，子图$G_{\pi}$包含一条从源结点s到结点v的唯一简单路径，且该路径也是图G里面从源结点s到结点v之间的一条最短路径，则前驱子图$G_{\pi}$是一棵广度优先树。广度优先树实际上就是一棵树，因为它是连通的，并且$|E_{\pi}|=|V_{\pi}|-1$。称$E_{\pi}$中的边为树边。

**当运行在一个邮箱或无向图G上时，BFS过程所建造出来的π属性使得前驱子图称为一棵广度优先树。**



## 深度优先搜索

深度优先搜索总是对最近才发现的结点v的出发边进行探索，直到该结点的所有出发边都被发现为止。一旦结点v的所有出发边都被发现，搜索则"回溯"到v的前驱结点(v是经过该结点才被发现的)，来搜索该前驱结点的出发边。该过程一直持续到从源结点可以达到的所有结点都被发现为止。如果还存在尚未发现的结点，则深度优先搜索将从这些未被发现的结点中任选一个作为新的源结点，并重复同样的搜索过程。该算法重复整个过程，直到图中的所有结点都被发现为止。

深度优先搜索的**前驱子图**的定义：

设图$G_{\pi}=(V, E_{\pi})，E_{\pi}=\{(v.{\pi},v)：v\in V且v.{\pi}\ne NIL\}$

深度优先搜索的前驱子图形成一个由多棵深度优先树构成的**深度优先森林**。森林$E_{\pi}$中的边仍然称为树边。

每个结点仅在一棵深度优先树中出现，所有的深度优先树是不相交的。

深度优先搜索算法还在每个结点盖上一个时间戳。一个记录结点第一次被发现的时间，一个记录的是搜索完成对结点的邻接链表扫描的时间。

```
DFS(G)
for each vertex u∈G.V
	u.color=WHITE
	u.π=NIL
time=0
for each vertex u∈G.V
	if u.color == WHITE
		DFS-VISIT(G,u)
		
DFS-VISIT(G,u)
time = time +1
u.d=time
u.color=GRAY
for each v∈G:Adj[u]
	if v.color==WHITE
		v.π=u
		DFS-VISIT(G,v)
u.color=BLACK
time = time +1
u.f=time
```

深度优先搜索算法的运行时间为$\Theta(V+E)$

**深度优先搜索的性质**

深度优先搜索最基本的性质是，其生成的前驱子图形成一个由多棵树所构成的森林。

深度优先搜索的另一个重要性质是，结点的发现时间和完成时间具有所谓的括号化结构(parenthesis structure)。如果以左括号"(u"来表示结点u的发现，以右括号"u)"来表示结点u的完成，则发现和完成的历史记载形成一个规整的表达式，即所有的括号都适当地嵌套在一起。

**在有向或无向图G的深度优先森林中，结点v是结点u的真后代当且仅当u.d<v.d<v.f<u.f成立**

**白色路径定理**

在有向或无向图的深度优先森林中，结点v是结点u的后代当且仅当在发现结点u的时间u.d，存在一条从结点u到结点v的全部由白色结点所构成的路径。

**边的分类**

可以通过搜索来对输入图的边进行分类。

**树边**：深度优先森林中的边。如果结点v是因算法对边(u,v)的探索而首先被发现，则(u,v)是一条树边。

**后向边**：后向边(u,v)是将结点u连接到其在深度优先树中(一个)祖先结点v的边。由于有向图中可以有自循环，自循环也被认为是后向边。

**前向边**：是将结点u连接到其在深度优先树中一个后代结点v的边(u,v)

**横向边**：指其他所有的边。这些边可以连接同一棵深度优先树中的结点，只要其中一个结点不是另外一个结点的祖先，也可以连接不同深度优先树中的两个结点。

当第一次探索边(u,v)时，

结点v为白色表明该条边(u,v)是一条树边。

结点v为灰色表明该条边(u,v)是一条后向边。

结点v为黑色表明该条边(u,v)是一条前向边或横向边。

**在对无向图G进行深度优先搜索中，从来不会出现前向边和横向边**

## 图结构的遍历(BFS/DFS)

### DFS

我们一般不用 `Vertex` 这样的类来存储图，但是这里还是先用一下这个类，以便大家把图的遍历和多叉树的遍历做对比。

```python
# 多叉树节点
class Node:
    def __init__(self, val=0, children=None):
        self.val = val
        self.children = children if children is not None else []

# 多叉树的遍历框架
def traverse(root):
    # base case
    if root is None:
        return
    # 前序位置
    print(f"visit {root.val}")
    for child in root.children:
        traverse(child)
    # 后序位置

# 图节点
class Vertex:
    def __init__(self, id=0, neighbors=None):
        self.id = id
        self.neighbors = neighbors if neighbors is not None else []

# 图的遍历框架
# 需要一个 visited 数组记录被遍历过的节点
# 避免走回头路陷入死循环
def traverse_graph(s, visited):
    # base case
    if s is None:
        return
    if visited.get(s.id, False):
        # 防止死循环
        return
    # 前序位置
    visited[s.id] = True
    print(f"visit {s.id}")
    for neighbor in s.neighbors:
        traverse_graph(neighbor)
    # 后序位置
```

可以看到，图的遍历比多叉树的遍历多了一个 `visited` 数组，用来记录被遍历过的节点，避免遇到环时陷入死循环。

有了上面的铺垫，就可以写出基于邻接表/邻接矩阵的图遍历代码了。虽然邻接表/邻接矩阵的底层存储方式不同，但提供了统一的 API，所以直接使用 `Graph` 接口的方法即可：

```python
# 遍历图的所有节点
def traverse(graph, s, visited):
    # base case
    if s < 0 or s >= len(graph):
        return
    if visited[s]:
        # 防止死循环
        return
    # 前序位置
    visited[s] = True
    print("visit", s)
    for e in graph.neighbors(s):
        traverse(graph, e.to, visited)
    # 后序位置
```

由于 `visited` 数组的剪枝作用，这个遍历函数会遍历一次图中的所有节点，并尝试遍历一次所有边，所以算法的时间复杂度是 O(E+V)O(E+V)，其中 `E` 是边的总数，`V` 是节点的总数。

	其实二叉树/多叉树的遍历函数，也要算上边的数量，只不过对于树结构来说，边的数量和节点的数量是近似相等的，所以时间复杂度还是 O(N+N)=O(N)O(N+N)=O(N)。
	
	树结构中的边只能由父节点指向子节点，所以除了根节点，你可以把每个节点和它上面那条来自父节点的边配成一对儿，这样就可以比较直观地看出边的数量和节点的数量是近似相等的。
	
	而对于图结构来说，任意两个节点之间都可以连接一条边，边的数量和节点的数量不再有特定的关系，所以我们要说图的遍历函数时间复杂度是 O(E+V)O(E+V)。

## 拓扑排序

对于一个有向无环图G=(V,E)来说，其拓扑排序是G中所有结点的一种线性次序，该次序满足如下条件：如果图G包含边(u,v)，则结点u在拓扑排序中处于结点v的前面(如果图G包含环路，则不可能排出一个线性次序)。

```
TOPOLOGICAL-SORT(G)
1 call DFS(G) to compute finishing times v.f for each vertex v
2 as each vertex is finished, insert it onto the front of a linked list
3 return the linked list of vertices
```

我们可以在$\Theta(V+E)$ 的时间内完成拓扑排序，因为深度优先搜索算法的运行时间为$\Theta(V+E)$，将结点插入到链表最前端所需的时间为$O(1)$，而一共只有|V|个结点需要插入。

**一个有向图G=(V,E)是无环的当且仅当对其进行的深度优先搜索不产生后向边**

**拓扑排序算法TOPOLOGICAL-SORT生成的是有向无环图的拓扑排序**

## 强连通分量

深度优先搜索的经典应用：将有向图分解为强连通分量。

图G=(V,E)的转置为$G^T=(V,E^T)$，这里$E^T=\{(u,v):(v,u)\in E\}$。给定图G的邻接链表，创建$G^T$的时间为O(V+E)。图G和$G^T$的强连通分量完全相同。

```
STRONGLY-CONNECTED-COMPONENTS(G)
1 call DFS(G) to compute finishing times u.f for each vertex u
2 compute G^T
3 call DFS(G^T), but in the main loop of DFS,conside the vertices
	in order of decreasing u.f (as computed in line 1)
4 output the vertices of each tree in the depth-first forest formed in line 3 as a separate strongly connected component
```

**分量图是一个有向无环图**

**设C和C'为有向图的两个不同的强连通分量。假如存在一条边(u,v)∈E，这里u∈C，v∈C'，则f(C)>f(C')**

**设C和C'为有向图的两个不同的强连通分量。假如存在一条边(u,v)∈$E^T$，这里u∈C，v∈C'，则f(C)<f(C')**



## 最小生成树

假定有一个连通无向图G=(V,E)和权重函数$w:E—> R$，我们希望找出图G的一棵最小生成树。最小生成树T是一个无环子集$T\subseteq E$，既能够将所有的结点连接起来，又具有最小的权重。**最小生成树是唯一的**

解决最小生成树问题的两种算法：Kruskal算法和Prim算法，它们都是贪心算法，但它们使用贪心策略的方式有所不同。如果使用普通的二叉堆，那么可以很容易地将这两个算法的时间复杂度限制在O(ElgV)的数量级内。但如果使用斐波那契堆，Prim算法的运行时间将改善为O(E+VlgV)。此运行时间在|V|远远小于|E|的情况下较二叉堆有很大改进。

这个贪心策略的通用方法：

```
GENERIC-MST(G,w)
1 A=∅
2 while A does not form a spanning tree
3 	find an edge(u,v) that is safe for A
4 	A=A∪{(u,v)}
5 return A
```

该通用方法在每个时刻生长最小生成树的一条边，并在整个策略的实施过程中，管理一个遵守下述循环不变式的边集合A：

*在每遍循环之前，A是某棵最小生成树的一个子集*

每一步选择一条边加入集合A中，使得A不违反循环不变式，这样的边称为集合A的**安全边**。

无向图G=(V,E)的一个切割(S,V-S)是集合V的一个划分。如果一条边$(u,v)\in E$的一个端点位于集合S，另一个端点位于集合V-S，则称该条边**横跨**切割(S,V-S)。如果集合A中不存在横跨该切割的边，则称该切割**尊重**集合A。在横跨一个切割的所有边中，权重最小的边称为**轻量级边**。注意，轻量级边可能不是唯一的。一般，如果一条边是满足某个性质的所有边中权重最小的，则称该条边是满足给定性质的一条轻量级边。

**辨认安全边的规则**

设G=(V,E)是一个在边E上定义了实数值权重函数w的连通无向图。设集合A为E的一个子集，且A包括在图G的某棵最小生成树中，设(S,V-S)是图G中尊重集合A的任意一个切割，又设(u,v)是横跨切割(S,V-S)的一条轻量级边。那么边(u,v)对于集合A是安全的。

**推论**

设G=(V,E)是一个在边E上定义了实数值权重函数w的连通无向图。设集合A为E的一个子集，且A包括在图G的某棵最小生成树中，并设$C=(V_c，E_c)$为森林$G_A=(V，A)$中的一个连通分量(树)。如果边(u,v)是连接C和$G_A$中某个其他连通分量的一条轻量级边，则边(u,v)对于集合A是安全的。   

### Kruskal算法

在Kruskal算法中，集合A是一个森林，其结点就是给定图的结点。每次加入到集合A中的安全边永远是权重最小的连接两个不同分量的边。

```
MST-KRUSKAL(G,w)
A=∅
for each vertex v∈ G.V
	MAKE-SET(v)    //每棵树仅包含一个结点
sort the edges of G.E into nondecreasing order by weight w
for each edge (u,v)∈ G.E,taken in nondecreasing order by weight
	if FIND-SET(u)≠FIND-SET(v)
		A=A∪{(u,v)}
		UNION(u,v)
return A
```

对于图G=(V,E)，Kruskal算法的运行时间依赖于不相交集合数据结构的实现方式。

==即每次选择最小权重的边加入集合中，前提是该边不会导致形成环路==



### Prim算法

在Prim算法里，集合A则是一棵树。每次加入到A中的安全边永远是连接A和A之外某个结点的边中权重最小的边。

这棵树从一个任意的根结点r开始，一直长大到覆盖V中的所有结点为止。

前提也是不能形成环路

```
MST-PRIM(G,w,r)
for each u∈G.V
	u:key=∞
	u:π=NIL
r:key=0   //以便使该结点成为第一个被处理的结点
Q=G.V
while Q≠∅
	u=EXTRACT-MIN(Q)   //横跨切割(V-Q,Q)的轻量级边的一个端点u,将其从Q中删除，加入到集合V-Q中
	for each v∈G.Adj[u]   //更新每一个与u邻接但不在树中的结点的key和π属性
	if v∈Q and w(u,v)<v.key
		v.π=u
		v.key=w(u,v)
```

所有不在数A中的结点都存放在一个基于key属性的最小优先队列Q中。对于每个结点v，属性v.key保存的是连接v和树中结点的所有边中最小边的权重。如果不存在这样的边,v.key=∞。属于v.π给出的是结点v在树中的父结点。

Prim算法的运行时间取决于最小优先队列Q的实现方式。

## 单源最短路径

